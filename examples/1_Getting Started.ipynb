{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/karnsaurabhkumar/soscipy/blob/master/examples/1_Getting%20Started.ipynb)\n",
    "\n",
    "\n",
    "# SoSciPy\n",
    "Soscipy is a python library to simplify working with data specially in social sciences. While there are several packages out there, I have personally found it difficult to find out the right library to stick to and the right recepies to use. Unlike other domain where computational methods have seen a rapid growth, social sciences remain a relatively unexplored area. This is first of the 4 tutorials which will explore data analysis in education. \n",
    "\n",
    "There are four parts to soscipy:\n",
    "- **Data Analysis** : Aims to make rapid analysis easy while not compromising on any functionalities and extendability\n",
    "- **Data Processing** : Makes common actions with structured data easy and accessible without needing expertiese in computer science\n",
    "- **Data Visualisation** : Rapid visualisations while ensuring that the output is publication quality\n",
    "- **Utilities** : A set of utilities that you can plug and play to make your workflow easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting soscipy\n",
      "  Downloading soscipy-0.0.24-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: soscipy\n",
      "  Attempting uninstall: soscipy\n",
      "    Found existing installation: soscipy 0.0.23\n",
      "    Uninstalling soscipy-0.0.23:\n",
      "      Successfully uninstalled soscipy-0.0.23\n",
      "Successfully installed soscipy-0.0.24\n"
     ]
    }
   ],
   "source": [
    "#Installation\n",
    "!pip install --upgrade soscipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from soscipy.process import dfops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_path = 'https://github.com/karnsaurabhkumar/soscipy/blob/master/data/gyan_data.csv?raw=true'\n",
    "f2_path = 'https://github.com/karnsaurabhkumar/soscipy/blob/master/data/rangin_justicehub-file.csv?raw=true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = pd.read_csv(f1_path)\n",
    "f2 = pd.read_csv(f2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = list(f1.iloc[:,0])\n",
    "list2 = list(f2.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = string_matcher(list1,list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_side</th>\n",
       "      <th>right_side</th>\n",
       "      <th>similairity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sharad Arvind Bobde</td>\n",
       "      <td>Sharad Arvind Bobde</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sharad Arvind Bobde</td>\n",
       "      <td>Sharad Arvind Bobde</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N.V. Ramana</td>\n",
       "      <td>N.V. Ramana</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N.V. Ramana</td>\n",
       "      <td>N.V. Ramana</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R.F. Nariman</td>\n",
       "      <td>R.F. Nariman</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>D.P. Madon</td>\n",
       "      <td>D.P. Madon</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>M.P. Thakkar</td>\n",
       "      <td>M.P. Thakkar</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>Sabyasachi Mukherjee</td>\n",
       "      <td>Sabyasachi Mukherjee</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Sabyasachi Mukherjee</td>\n",
       "      <td>Sabyasachi Mukherjee\\r\\n</td>\n",
       "      <td>0.929294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Ranganath Misra</td>\n",
       "      <td>Ranganath Misra</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                left_side                right_side  similairity\n",
       "0     Sharad Arvind Bobde       Sharad Arvind Bobde     1.000000\n",
       "1     Sharad Arvind Bobde       Sharad Arvind Bobde     1.000000\n",
       "2             N.V. Ramana               N.V. Ramana     1.000000\n",
       "3             N.V. Ramana               N.V. Ramana     1.000000\n",
       "4            R.F. Nariman              R.F. Nariman     1.000000\n",
       "..                    ...                       ...          ...\n",
       "489            D.P. Madon                D.P. Madon     1.000000\n",
       "490          M.P. Thakkar              M.P. Thakkar     1.000000\n",
       "491  Sabyasachi Mukherjee      Sabyasachi Mukherjee     1.000000\n",
       "492  Sabyasachi Mukherjee  Sabyasachi Mukherjee\\r\\n     0.929294\n",
       "493       Ranganath Misra           Ranganath Misra     1.000000\n",
       "\n",
       "[494 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.get_matched_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def matrix_max_val_loc(mat):\n",
    "    return np.unravel_index(np.argmax(mat, axis=None), mat.shape)\n",
    "\n",
    "\n",
    "def intersection_count(l1, l2):\n",
    "    return set(l1).intersection(set(l2))\n",
    "\n",
    "\n",
    "def prim_key_candidate(dataframe):\n",
    "    val = {}\n",
    "    for i, c in enumerate(dataframe):\n",
    "        val[i] = len(dataframe[c].unique())\n",
    "    temp = sort_dict(val)\n",
    "    temp = list(temp.keys())[-3:]\n",
    "    temp.sort()\n",
    "    return temp\n",
    "\n",
    "\n",
    "def sort_dict(dictionary):\n",
    "    \"\"\"\n",
    "    Takes a dictionary as an input and sorts the dictionary\n",
    "    :param dictionary: a key value pair dictionary\n",
    "    :return: a sorted dictionar\n",
    "    \"\"\"\n",
    "    return dict(sorted(dictionary.items(), key=lambda item: item[1]))\n",
    "\n",
    "\n",
    "def invert_dict(dictionary):\n",
    "    \"\"\"\n",
    "    Takes a dictionary as input and reverse the key value pair\n",
    "    :param dictionary: a key value pair dictionary\n",
    "    :return: a sorted dictionary\n",
    "    \"\"\"\n",
    "    return {v: k for k, v in dictionary.items()}\n",
    "\n",
    "\n",
    "def get_primary_keys(df1, df2):\n",
    "    candidates = np.zeros((3, 3))\n",
    "    temp1 = prim_key_candidate(df1)\n",
    "    temp2 = prim_key_candidate(df2)\n",
    "    for i in range(len(temp1)):\n",
    "        for j in range(len(temp2)):\n",
    "            l1 = df2[df2.columns[temp1[i]]].values\n",
    "            l2 = df1[df1.columns[temp2[j]]].values\n",
    "            candidates[i][j] = len(intersection_count(l1, l2))\n",
    "    if candidates.max() <= 0:\n",
    "        return -1, -1\n",
    "    else:\n",
    "        return matrix_max_val_loc(candidates)\n",
    "\n",
    "\n",
    "def combine(df1, df2, outer=True):\n",
    "    \"\"\"\n",
    "    Combines two dataframe after identifying its primary key\n",
    "    :param df1: Dataframe1\n",
    "    :param df2: Dataframe2\n",
    "    :param outer: bool, if set True will return outer join of the dataset\n",
    "    :return: a joint dataframe\n",
    "    \"\"\"\n",
    "    left_on, right_on = get_primary_keys(df1, df2)\n",
    "    list1 = list(df1[df1.columns[left_on]])\n",
    "    list2 = list(df2[df2.columns[right_on]])\n",
    "    primary_key_joins = string_matcher(list1, list2)\n",
    "    matched_list = primary_key_joins.get_matched_list()\n",
    "    matched_list = matched_list[matched_list.similairity < 0.99]\n",
    "    df2[df2.columns[right_on]] = df2[df2.columns[right_on]].apply(lambda x: lookup(x, matched_list))\n",
    "    if outer:\n",
    "        temp = pd.merge(df1, df2, left_on=df1.columns[left_on], right_on=df2.columns[right_on], how='outer')\n",
    "    else:\n",
    "        temp = pd.merge(df1, df2, left_on=df1.columns[left_on], right_on=df2.columns[right_on])\n",
    "        temp = temp.drop([df2.columns[right_on]], axis=1)\n",
    "    return temp\n",
    "\n",
    "\n",
    "def lookup(string, matches_df):\n",
    "    \"\"\"\n",
    "    Lookup function to identify the similar name from the matched list\n",
    "    :param string: Input string for the left side dataframe\n",
    "    :param matches_df: Matched string table\n",
    "    :return: output string\n",
    "    \"\"\"\n",
    "    val = matches_df[matches_df['left_side'] == string]['right_side']\n",
    "    if len(val) > 0:\n",
    "        return val.values[0]\n",
    "    else:\n",
    "        return string\n",
    "\n",
    "\n",
    "def rename_pd(data, col_name, new_col_name):\n",
    "    \"\"\"\n",
    "    Function to return renamed columns for a pandas dataframe\n",
    "    :param data: Dataframe as input\n",
    "    :param col_name: List of column names that needs to be renamed\n",
    "    :param new_col_name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert type(col_name) == list, 'Column names must be a list of strings'\n",
    "    assert type(new_col_name) == list, 'New column names must be a list of strings'\n",
    "    assert len(col_name) == len(new_col_name), 'Length of column names and new names must be equal'\n",
    "    assert all(elem in data.columns for elem in col_name)\n",
    "    columns = {}\n",
    "    for loc, col in enumerate(col_name):\n",
    "        columns[col] = new_col_name[loc]\n",
    "    data = data.rename(columns=columns)\n",
    "    assert isinstance(data, object)\n",
    "    return data\n",
    "\n",
    "\n",
    "class string_matcher():\n",
    "    def __init__(self, list1, list2, top_n=10, similarity=0.8):\n",
    "        self.list1 = list1\n",
    "        self.list2 = list2\n",
    "        self.names = self.list1 + self.list2\n",
    "        self.top_n = top_n\n",
    "        self.similarity = similarity\n",
    "\n",
    "    def ngrams(self, string, n=3):\n",
    "        string = re.sub(r'[,-./]|\\sBD', r'', string)\n",
    "        ngrams = zip(*[string[i:] for i in range(n)])\n",
    "        return [''.join(ngram) for ngram in ngrams]\n",
    "\n",
    "    def awesome_cossim_top(self, A, B, ntop ,lower_bound=0):\n",
    "        # force A and B as a CSR matrix.\n",
    "        # If they have already been CSR, there is no overhead\n",
    "        A = A.tocsr()\n",
    "        B = B.tocsr()\n",
    "        M, _ = A.shape\n",
    "        _, N = B.shape\n",
    "\n",
    "        idx_dtype = np.int32\n",
    "\n",
    "        nnz_max = M * ntop\n",
    "\n",
    "        indptr = np.zeros(M + 1, dtype=idx_dtype)\n",
    "        indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "        data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "\n",
    "        ct.sparse_dot_topn(\n",
    "            M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "            np.asarray(A.indices, dtype=idx_dtype),\n",
    "            A.data,\n",
    "            np.asarray(B.indptr, dtype=idx_dtype),\n",
    "            np.asarray(B.indices, dtype=idx_dtype),\n",
    "            B.data,\n",
    "            ntop,\n",
    "            lower_bound,\n",
    "            indptr, indices, data)\n",
    "\n",
    "        return csr_matrix((data, indices, indptr), shape=(M, N))\n",
    "\n",
    "    def get_matches_df(self, sparse_matrix, name_vector, top=100):\n",
    "        non_zeros = sparse_matrix.nonzero()\n",
    "        sparserows = non_zeros[0]\n",
    "        sparsecols = non_zeros[1]\n",
    "\n",
    "        if top:\n",
    "            nr_matches = top\n",
    "        else:\n",
    "            nr_matches = sparsecols.size\n",
    "\n",
    "        left_side = np.empty([nr_matches], dtype=object)\n",
    "        right_side = np.empty([nr_matches], dtype=object)\n",
    "        similairity = np.zeros(nr_matches)\n",
    "\n",
    "        for index in range(0, nr_matches):\n",
    "            left_side[index] = name_vector[sparserows[index]]\n",
    "            right_side[index] = name_vector[sparsecols[index]]\n",
    "            similairity[index] = sparse_matrix.data[index]\n",
    "\n",
    "        return pd.DataFrame({'left_side': left_side,\n",
    "                             'right_side': right_side,\n",
    "                             'similairity': similairity})\n",
    "\n",
    "    def get_matched_list(self):\n",
    "        # TODO: Add filter to remove exact matches\n",
    "        vectorizer = TfidfVectorizer(min_df=1, analyzer=self.ngrams)\n",
    "        tf_idf_matrix = vectorizer.fit_transform(self.names)\n",
    "        matches = self.awesome_cossim_top(tf_idf_matrix, tf_idf_matrix.transpose(), self.top_n, self.similarity)\n",
    "        matches_df = self.get_matches_df(matches, self.names, top=len(self.names))\n",
    "        return matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
